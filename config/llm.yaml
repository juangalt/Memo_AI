# LLM Provider Configuration and API Settings
# Memo AI Coach - LLM Configuration

provider:
  name: "claude"
  api_base_url: "https://api.anthropic.com"
  model: "claude-3-haiku-20240307"
  api_version: "2023-06-01"

api_configuration:
  api_key: "${CLAUDE_API_KEY}"
  timeout: 30
  max_retries: 3
  retry_delay: 1
  max_tokens: 4000
  temperature: 0.7
  top_p: 0.9
  frequency_penalty: 0.0
  presence_penalty: 0.0
  # High Priority: Add validation field requirements
  api_key_required: true
  timeout_validation: true
  max_retries_validation: true
  max_tokens_validation: true

request_settings:
  max_text_length: 10000
  min_text_length: 10
  chunk_size: 2000
  overlap_size: 200
  # High Priority: Add validation field requirements
  max_text_length_validation: true
  min_text_length_validation: true
  text_length_validation: true  # Ensures max > min

response_handling:
  parse_json: true
  validate_response: true
  extract_structured_data: true
  handle_partial_responses: true
  retry_on_failure: true

error_handling:
  rate_limit_retry: true
  rate_limit_delay: 60
  max_rate_limit_retries: 3
  timeout_retry: true
  max_timeout_retries: 2
  fallback_response: true

debug_settings:
  log_requests: true
  log_responses: true
  log_timing: true
  log_errors: true
  store_raw_prompts: true
  store_raw_responses: true

performance_optimization:
  connection_pooling: true
  max_connections: 10
  connection_timeout: 10
  request_timeout: 30
  response_timeout: 30
  # High Priority: Add performance optimization for <15 seconds requirement
  target_response_time: 12  # Target under 15 seconds
  response_time_alert_threshold: 14  # Alert at 14 seconds
  max_response_time: 15  # Hard limit at 15 seconds
  performance_alerting: true
  response_time_tracking: true
  # High Priority: Add concurrent request optimization
  max_concurrent_requests: 5
  request_queue_size: 10
  request_priority_queue: true
  # High Priority: Add caching for repeated requests
  enable_response_caching: true
  cache_ttl: 3600  # 1 hour cache
  cache_max_size: 1000

monitoring:
  track_response_times: true
  track_error_rates: true
  track_token_usage: true
  track_cost_metrics: true
  alert_on_failures: true
  # High Priority: Add performance monitoring for <15 seconds requirement
  track_performance_metrics: true
  performance_alerting: true
  response_time_thresholds:
    warning: 12  # seconds
    critical: 14  # seconds
    failure: 15   # seconds
  performance_reporting: true
  real_time_monitoring: true

fallback_configuration:
  enable_fallback: true
  fallback_provider: "openai"
  fallback_model: "gpt-3.5-turbo"
  fallback_api_key: "${FALLBACK_API_KEY}"
  fallback_conditions:
    - "rate_limit_exceeded"
    - "service_unavailable"
    - "timeout_error"
    - "authentication_error"

cost_management:
  track_costs: true
  cost_limit_per_request: 0.50
  cost_limit_per_day: 10.00
  cost_limit_per_month: 100.00
  alert_on_cost_limit: true
  auto_fallback_on_cost_limit: true

security:
  api_key_rotation: false
  key_rotation_interval: 90
  secure_transmission: true
  data_encryption: true
  audit_logging: true

model_specific_settings:
  claude:
    max_input_tokens: 200000
    max_output_tokens: 4000
    system_message_support: true
    function_calling: false
    vision_support: false
    
  openai:
    max_input_tokens: 4096
    max_output_tokens: 1000
    system_message_support: true
    function_calling: true
    vision_support: false
    
  gemini:
    max_input_tokens: 30720
    max_output_tokens: 2048
    system_message_support: false
    function_calling: false
    vision_support: true

# High Priority: Add validation rules section for devspec compliance
validation_rules:
  # Required field validation
  api_key_required: true
  timeout_range: [10, 300]  # seconds
  max_retries_range: [0, 10]
  max_tokens_range: [100, 8000]
  max_text_length_range: [1000, 50000]
  min_text_length_range: [10, 1000]
  # Performance validation for <15 seconds requirement
  target_response_time: 12  # seconds
  max_response_time: 15     # seconds
  performance_validation: true
  # Provider validation
  supported_providers: ["claude", "openai", "gemini"]
  provider_validation: true

environment_specific:
  development:
    debug_mode: true
    log_level: "DEBUG"
    mock_responses: true
    cost_tracking: false
    # High Priority: Add development performance settings
    target_response_time: 10  # Faster in development
    performance_alerting: false
    
  production:
    debug_mode: false
    log_level: "INFO"
    mock_responses: false
    cost_tracking: true
    fallback_enabled: true
    # High Priority: Add production performance settings
    target_response_time: 12  # Strict <15 seconds requirement
    performance_alerting: true
    performance_monitoring: true
